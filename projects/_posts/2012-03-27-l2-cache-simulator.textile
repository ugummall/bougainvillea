--- 
layout: post
title: L2 Cache Simulator
subcat: software
image: /img/thumbs/l2cache.png
description: Simulates a set associative, write-allocate, MESI L2 cache.
---

Our term project for the microprocessor system design course at Portland State in the Fall 2011 quarter was to write a small program in Verilog, C, or C++ to simulate (not synthesize) the behavior of a write-allocate, MESI protocol, four-way set associative L2 cache with 4K lines of 64 bytes data each. 

We successfully wrote our program in C and passed the course. Having written most of the code myself, I could see a lot of areas where I could improve it and so, with permission from my partners, I rewrote the code over winter break to be easily extensible to different sizes and set associativities of cache. I shrunk the program from 646 lines to 377 lines, cutting it by 42%, and made it much cleaner and easier to follow. The sample input and output are at the bottom, and all the files (and commit history) are available at my <a href="http://github.com/wicker/l2cache/">GitHub repository</a> under the MIT license.

<strong>Background</strong>

It's standard practice for a computer's processor to contain caches, either on the chip or very physically nearby, which are basically areas of reserved space to store information between the processor and its full main memory. Access times to the main memory are many times larger than access times to the cache; for example, a cache access could take a few nanoseconds where a memory access could take more than a hundred. Therefore, it's in the CPU's interest to try to store data in the cache that it will likely need in the near future. 

A common configuration is to have multiple levels of caches, from a typically much smaller on-chip L1 cache to an off-chip L2 or L3 cache which might be relatively larger. In a dual-core processor,each processor probably has its own on-chip L1 cache but may or may not share a single L2 cache. 

Now, it's relatively simple to handle storing into and evicting from a cache if only one processor has access. For example, the "Least Recently Used" eviction policy uses one or more bits of the item to indicate which item in a particular index is the oldest, and thus the least likely to be used again in the near future. Thus, when the processor needs to add a new item into that index line, it knows which of the items in the index can be safely replaced.

It gets a little more complicated when other considerations and extra processors come into place. An item might be recently written to memory but its counterpart in the cache simply has its bits marked 'dirty' because it hasn't been replaced yet. But then which item should be evicted if the cache index in question has both an item with a dirty bit and an item marked least-recently-used? What if one of two processors updates something in memory and sets the dirty bit in the L2 cache -- how does the other processor know to invalidate their own copy in their own L1 cache, which the first processor can't see?

This is called cache coherency and it can be addressed in a wide variety of ways. Our solution implemented the <a href="http://en.wikipedia.org/wiki/MESI_protocol">MESI</a> (Modified-Exclusive-Shared-Invalid) protocol which depended on modifying two bits (for the four possibilities) and checking those and the LRU bit to make eviction and write decisions.

<strong>Simulating the L2 Cache in C</strong>

Our term project for the microprocessor system design course at Portland State in the Fall 2011 quarter was to write a small program in Verilog, C, or C++ to simulate (not synthesize) the behavior of a write-allocate, MESI protocol, four-way set associative L2 cache with 4K lines of 64 bytes data each. Our C program was tested by our professor by running a text file containing lines of the type

<div class="code">'n address'</div>

where

<div class="code">'n' could be 0-9 and indicated the desired operation type and'

'address' was some 32-bit address.</div>

Upon a command input of '9' the cache would send (in a somewhat pretty format) all the lines that had been accessed to an output file. We were not required to move, track, or otherwise handle any actual data in the cache. We only had to track addresses and cache locations.

<strong>Extending the Cache</strong>

I felt that the quality of the code, especially after last-minute fixes, could be improved. Our prof challenged me to improve extensibility so that it would take less than fifteen minutes to change the size (number of lines) or set associativity (direct-mapped, fully associative).

The original file (<a href="https://raw.github.com/wicker/l2cache/master/original.c">original.c</a>) had 646 lines, used 'while' loops, assumed a four-way cache and so specified 0-3 for all functions that checked all ways in an index. It haphazardly included DRAM and L1 printf access notes for testing and display, which we thought at the time was a good idea to keep track of what was going on but they were inconsistent and really failing for any functional purpose. The cache also repeated sections of code instead of calling a function and, finally, it failed on the case of cache coherency.

I spent a week over winter break and tried to fix most of those problems.

The final revised version (<a href="https://raw.github.com/wicker/l2cache/master/main.c">main.c</a>) has 377 lines, uses 'for' loops, and depends on a global variable to set cache size and can thus be used to simulate a direct mapped or x-way set associative cache. It contains no DRAM or L1 printf access notes as they were outside the scope of the simulation and, again, never followed up on in the first place. The focus was the cache - not the things to which the cache was connected. This version makes use of functions where appropriate, has an overhauled LRU algorithm that's much more simple, and makes use only of a single output file for the display.

The final cache simulator still fails on one of the cases of cache coherency but I added a script to simplify testing/running the whole thing and, anyway, you can't have everything you want in life.

<strong>Get the Code</strong>

&raquo; <a href="http://github.com/wicker/l2cache/">GitHub repository</a>

To run this cache, you will need the following files:

<div class="code"><a href="https://raw.github.com/wicker/l2cache/master/main.c">main.c</a> - contains the program itself

<a href="https://raw.github.com/wicker/l2cache/master/testfile.din">testfile.din</a> - the list of 'n' 'address' inputs

<a href="https://raw.github.com/wicker/l2cache/master/Makefile">Makefile</a> - for ease of removing and compiling files during test

<a href="https://raw.github.com/wicker/l2cache/master/run">run</a> - this is the script</div>

Download these four files into one directory and cd to that directory. Then give the script 'run' permission to run and then ... run it. 

<div class="code">chmod u+x run
./run</div>

<strong>Script</strong>

main.c will take in the testfile.din and printf the stats of the entire run.

It will also generate a display.txt on every iteration where n = 9. This will display everything in the cache but make no changes. The cache will be reset on every iteration where n = 8.

<div class="code">#!/bin/bash
# Test the L2 cache
make clean
make all
./main
cat display.txt</div>

<strong>Sample Input</strong>

 <img src="https://jenner.smugmug.com/JennerHanniNet/i-VJZxsqn/0/M/l2cache-input-M.png">

<strong>Sample Output</strong>

 <img src="https://jenner.smugmug.com/JennerHanniNet/i-BPFGhL9/0/L/l2cache-output-L.png">
 

